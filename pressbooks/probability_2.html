<!-- Chapter 2. Probability theory -->
<p class="p1" style="text-align: right"><em>It is through the calculation of probabilities</em></p>
<p class="p1" style="text-align: right"><em>that the divine order becomes visible.</em></p>
<p class="p1" style="text-align: right">— Jacob Bernoulli</p>
&nbsp;

<p class="indent" style="text-align: justify; text-indent: 2em">A large part of history of science could be summarized as a continuous effort to translate observations of reality into precise, mathematical terms. To define mathematically the phenomena we find in the natural world, it is necessary to develop tools that express the one or more relevant quantities—sometimes called <em>variables—</em>and how they relate or change depending on one another. The purpose of such modelling might be, for instance, to determine the distance from the earth to the sun, to estimate the number of stars in the observable universe, or relating the number of lung cancer patients to pollution levels around smoking areas.</p>
<p class="indent" style="text-align: justify; text-indent: 2em">It has been said that mathematics could be summarized as all tasks related to <em>count</em>, <em>measure</em>, and <em>sort</em>. In a similar way, we could summarize all statistical issues as concern with <em>uncertainty</em>, or <em>variation</em> among observations. The word <em data-start="9" data-end="21">statistics</em> entered the English language through the work British politician and military officer John Sinclair, who in 1791 began publishing his monumental <em data-start="138" data-end="171">Statistical Account of Scotland, a </em>series of documentary publications covering life in Scotland in the 18th, 19th and 20th centuries. Adapting the German <em data-start="193" data-end="204">Statistik</em>—then denoting the descriptive study of states and their conditions—Sinclair expanded the term’s meaning to encompass “<em>an inquiry into the state of a country with respect to the happiness of its inhabitants</em>.” In doing so, he bridged the administrative traditional sense of the term with an empirical spirit that foreshadowed modern social science, into a discipline devoted to the systematic understanding of society itself. Through this chapter we will introduce terms such as description of populations, sampling, and chance. In further chapters we will develop and revisit ideas such as <em>randomness</em>, <em>relationship</em>, <em>correlation</em>, <em>confidence</em> and <em>reproducibility</em>, among others [...].</p>
<p class="indent" style="text-align: justify; text-indent: 2em">Historically, uncertainty has been associated with games of chance and gambling. The Royal Statistical Society, together with many other statistical groups, was originally set up to just <em>gather and publish data</em>, as an attempt to reduce its uncertainty. It remains an essential part of statistical activity today, and most Governments have statistical offices whose function is the plain acquisition and presentation of statistics. It did not take long before statisticians wondered how the data might best be used, and modern <em>statistical inference</em> was born.</p>
<p class="indent" style="text-align: justify; text-indent: 2em">The mathematical formalization of decision-making is actually quite a recent development. It is usually attributed to British mathematician Frank P. Ramsey (1903–1930), who in his 1926 paper <em>"Truth and Probability"</em> [...] introduced a formal, subjective interpretation of probability, laying the groundwork for what later became expected utility theory in decision-making under uncertainty. In short, Ramsey formalized how rational agents should assign probabilities and make decisions based on personal beliefs and preferences. All starting from the apparently simple question <em>"how should we make decisions in the face of uncertainty?"</em>.</p>
<p class="indent" style="text-align: justify; text-indent: 2em">Descriptive statistics gives us the tools to summarize, organize, and present data. By distilling observations into meaningful summaries, we find the first sense of order in apparent chaos. Descriptive statistics revolves around a few fundamental objects: data points, distributions, and summaries. Measures of central tendency—mean, median, mode—capture the “typical” observation, while measures of spread—variance, standard deviation, interquartile range—reveal how much observations fluctuate. Graphical tools such as histograms, box plots, and scatterplots turn abstract numbers into visible patterns, making insights immediate and intuitive. The development of measures like mean, median, and standard deviation emerged from this drive to quantify central tendencies and variability, giving rise to a shared language for describing empirical reality. The practical problems of descriptive statistics are deceptively simple: How do we summarize hundreds or thousands of observations? How do we detect patterns or outliers? How can we compare datasets rigorously? Each question demands careful choice of measure, sensitivity to data structure, and awareness of limitations. The challenge lies not in calculation alone, but in interpretation: a summary is meaningful only if it faithfully represents the underlying phenomena [...].</p>

<!-- 1.1. What is probability? -->
 <h3 style="text-align: justify">1.1. What is probability?</h3>

 <!-- 1.2. Discrete events -->
 <h3 style="text-align: justify">1.2. Discrete events</h3>

  <!-- 1.3. Continuous events -->
 <h3 style="text-align: justify">1.3. Continuous events</h3>

  <!-- 1.4. Expected value of a random variable -->
 <h3 style="text-align: justify">1.4. Expected value of a random variable</h3>
