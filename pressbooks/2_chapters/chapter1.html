<section class="chapter">

<h1>Descriptive statistics</h1>

<blockquote class="epigraph">
  <p class="epigraph-text">Statistics is the grammar of science.</p>
  <cite class="epigraph-author">— Karl Pearson</cite>
</blockquote>

<p>As a first approach to probabilty and statistics, we should properly define both topics and their main fields of study. Even deeply related, and both rooted in <em>combinatorics</em>—the study of uncertainty and things that change—they constitute well differentiated fields of mathematical analysis. A clear distinction often made is that probability is a <em>predictive</em> branch of mathematics, dealing with random events, also referred to as <em>stochastic</em>, aiming to compute expected values for such unknown outcomes. On the other hand, statistics would be a <em>descriptive</em> way of dealing with uncertainty, by sampling finite sets of observations from a given population, and building informative quantities, called statistical <em>estimators</em> to explore central tendency and variation. Such distinction has been extensively debated and discussed by mathematicians, experimental scientists, and philosoplers of science.</p>

<div class="medskip"></div>

<p>As a rule of thumb, probability provides a formal language for modelling uncertainty, whereas statistics concerns the epistemic problem of learning from data. Through this chapter we will introduce basic ideas on statistical inference such as population, sampling, and estimators of central tendency and variation, together with some notions of representation and visualization. The foundations of probability theory, rooted in the works of Bernoulli, Laplace, and Gauss, among others, will be covered in Chapter&nbsp;2. Hence, a philosophical position often adopted is that statistics is essentially the study of uncertainty, and that the statistician’s role is to assist other fields who encounter uncertainty in their work. In practice, there is a restriction in that statistics is ordinarily associated with data; and it is the link between the uncertainty, or variability, in the data and that in the topic itself that has occupied statisticians. Statistics does not have a monopoly of studies of uncertainty. Probability discusses how randomness in one part of a system affects other parts.</p>

<div class="medskip"></div>

<p>As a note, let us emphasize how these two approaches can and do coexist in science. We have many times heard that science works by making hypothesis and then predictions, that are compared and bechmarked with an experiment. This is a simplification, and it is not always true. Some sciences, like Newtonian mechanics, most of physics, chemistry, and certainly parts of biology, do rely on building accurate models and predictions, that are later compared with an experimental result. A clear example would be to use Newtonian mechanics as our theory, or model, to compute a prediction on where and when would a stone fall if I throw it. Then the experiment would be simply to measure, when and where. On the other hand, the archetypical example of an inference problem, which does not aim to build a prediction, but to give—or <em>reconstruct</em> or <em>infer</em>—an explanation given a set of observations, would be Darwinian evolution. This distinction is worth mentioning, since the usual definitions of sciences tend to rely heavily on the predictive power, which can be inaccurate and misleading […]. Different sciences may strongly differ on methods, instrumentation, or conceptual tools, but they are all equally legitimate.</p>

<hr>

<h2>Sampling and data types</h2>

<p>A large part of history of science could be summarized as a continous effort to translate observations of reality into precise, mathematical terms. To such endeavour, of describing the vast phenomena we find in the natural world with numerical language, it is necessary to develop tools that relate the one or more relevant quantities—sometimes called <em>variables</em>—and how they relate or change depending on one another.</p>

<div class="medskip"></div>

<p>In the same way mathematics as a whole has been summarized as three simple tasks—<em>count</em>, <em>measure</em>, and <em>sort</em>—we could group statistical problems in three main groups. The problem of <em>sampling</em>, the <em>estimation</em>, and finally <em>visualization</em>. Again, all of these problems are related to the phenomenon of <em>uncertainty</em>, or <em>variation</em> among measurements.</p>

<div class="medskip"></div>

<p>Hence, all statistical inquiries begin with observations and measurements, which we normally refer to as <em>data</em>. And data begins with the act of selection, or <em>sampling</em>. This distinction gives rise to two central notions: the <em>population</em>, which we denote by \( \mathcal{P} \), represents the complete set of all possible observations under study. We will write it as</p>

<div class="medskip"></div>

<p>\[
\mathcal{P} = \{x_1, x_2, \dots, x_N\}.
\]</p>

<div class="medskip"></div>

<p>The <em>sample</em> \( \mathcal{S} \), on the other hand, is the finite subset actually collected. For a series of \( N \) observations \( x_1, x_2, \dots, x_N \), a sample of just \( n \) elements is defined as</p>

<div class="medskip"></div>

<p>\[
\mathcal{S} = \{x_1, x_2, \dots, x_n\}, \quad n < N.
\]</p>

<div class="medskip"></div>

<p>where the elements \( x_i \) consist of just a selected group of observations from the population, not necessarily consecutive or in the same order. The population represents the ideal object of inference, while the sample is the concrete, finite evidence available to us.</p>

<div class="medskip"></div>

<p>Equally important is the recognition that not all data is equal. A common distinction is to consider <em>categorical</em> and <em>numerical</em> data.</p>

<div class="medskip"></div>

<p>The other big family is normally referred to as numerical—or <em>quantitative</em>—data.</p>

<div class="medskip"></div>

<p>Distinguishing between these types is no mere slang; different types of observations require different mathematical tools.</p>

<div class="medskip"></div>

<p>As a summary, sampling and proper description of data establish the ground upon which statistics is built.</p>

<div class="medskip"></div>

<p>Andrew Lang’s famous quote <em>“most people use statistics as a drunken man uses lamp-posts—for support rather than illumination”</em> highlights the tendency to use statistics as a crutch rather than as a tool for understanding.</p>

<hr>

<h2>Central tendency and variation</h2>

<p>Once we have a clear distinction between the population under study and the selected sample, we face a problem. Neither the population mean \( \mu \), nor its variance \( \sigma^2 \), are available to us.</p>

<div class="medskip"></div>

<p>The <em>sample mean</em> is defined as</p>

<div class="medskip"></div>

<p>\[
\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i.
\]</p>

<div class="medskip"></div>

<p>The <em>median</em> of an ordered sample is defined as</p>

<div class="medskip"></div>

<p>\[
M =
\begin{cases}
x_{(k+1)}, & n = 2k+1, \\
\dfrac{x_{(k)} + x_{(k+1)}}{2}, & n = 2k.
\end{cases}
\]</p>

<div class="medskip"></div>

<p>The <em>sample variance</em> is defined as</p>

<div class="medskip"></div>

<p>\[
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2.
\]</p>

<div class="medskip"></div>

<p>The <em>standard deviation</em> is</p>

<div class="medskip"></div>

<p>\[
s = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}.
\]</p>

<div class="medskip"></div>

<p>Finally, the \( p \)-th quantile satisfies</p>

<div class="medskip"></div>

<p>\[
Q_p = \inf\{x : F(x) \ge p\}.
\]</p>

<div class="medskip"></div>

<p>Variation is not merely a technicality; it is the very essence of uncertainty.</p>

<hr>

<h2>Data visualization</h2>

<p>While numerical summaries are useful, the human mind often understands patterns much faster through vision than calculation. By <em>data visualization</em> we mean techniques that transform numbers into shapes and structures that can be grasped at a glance.</p>

<hr>

<h3>Exercises</h3>

<ol>
  <li>Exercise […]</li>
  <li>Exercise […]</li>
  <li>Exercise […]</li>
</ol>

</section>
